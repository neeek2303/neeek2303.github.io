<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Nikita Drobyshev</title>

    <meta name="author" content="Nikita Drobyshev">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/elephant.svg" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

    
  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Nikita Drobyshev
                </p>
                <p>ML Research Engineer at Meta. Working on human avatars and generative AI. MS @ Skoltech. Ex-Samsung.</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:nikita.drobyshev23@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/ND_CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=itNst7wAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/NikDrob23/">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/neeek2303/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/ND_base.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/ND_base.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about human face/head generation and manipu. Representative papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="EP_stop()" onmouseover="EP_start()"  bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='EP_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/EP_sat.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/EP_sat.jpg' width="160">
        </div>
        <script type="text/javascript">
          function EP_start() {
            document.getElementById('EP_image').style.opacity = "1";
          }

          function EP_stop() {
            document.getElementById('EP_image').style.opacity = "0";
          }
          EP_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="http://jonbarron.info/mipnerf360">
          <span class="papertitle">Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields</span>
        </a>
        <br>
        <strong>Jonathan T. Barron</strong>,
        <a href="https://bmild.github.io/">Ben Mildenhall</a>,
        <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
        <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
        <a href="https://phogzone.com/">Peter Hedman</a>
        <br>
        <em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="http://jonbarron.info/mipnerf360">project page</a>
        /
        <a href="https://arxiv.org/abs/2111.12077">arXiv</a>
        /
        <a href="https://youtu.be/zBSH-k9GbV4">video</a>
        <p></p>
        <p>mip-NeRF can be extended to produce realistic results on unbounded scenes.</p>
      </td>
    </tr> 

              

    <tr onmouseout="LM_stop()" onmouseover="LM_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='LM_image'><video  width=100% muted autoplay loop>
          <source src="images/LM.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/LM.png' width=100%>
        </div>
        <script type="text/javascript">
          function LM_start() {
            document.getElementById('LM_image').style.opacity = "1";
          }

          function LM_stop() {
            document.getElementById('LM_image').style.opacity = "0";
          }
          LM_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://sites.google.com/view/laughing-matters/">
          <span class="papertitle">Laughing Matters: Introducing Laughing-Face Generation using Diffusion Models</span>
        </a>
        <br>
          								
		<a href="">Antoni Bigata Casademunt</a>,
		<a href="">Rodrigo Mira</a>,
          <strong>Nikita Drobyshev</strong>,
		<a href="">Konstantinos Vougioukas</a>,
		<a href="">Peter Zhizhin</a>,
		<a href="">Jean-Fran√ßois Thibert</a>,
        <a href="">Stavros Petridis</a>,
        <a href="">Maja Pantic</a>,
		
        <br>
        <em>BMVC</em>, 2023
        <br>
        <a href="https://sites.google.com/view/laughing-matters/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=TuyIp3b4_Jo">video</a>
        /
        <a href="https://arxiv.org/abs/2305.08854">arXiv</a>
        <p></p>
        <p>
        Model that creates realistic laughter animations from a still image and laughter audio, using advanced diffusion models.
        </p>
      </td>
    </tr>
	


    <tr onmouseout="MP_stop()" onmouseover="MP_start()"  bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='MP_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/MP.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/MP.png' width="160">
        </div>
        <script type="text/javascript">
          function MP_start() {
            document.getElementById('MP_image').style.opacity = "1";
          }

          function MP_stop() {
            document.getElementById('MP_image').style.opacity = "0";
          }
          MP_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://neeek2303.github.io/MegaPortraits/">
          <span class="papertitle">MegaPortraits: One-shot Megapixel Neural Head Avatars
</span>
        </a>
        <br> 
        <strong>Nikita Drobyshev</strong>,
        <a href="">Jenya Chelishev</a>,
        <a href="">Taras Khakhulin</a>,
        <a href="">Aleksei Ivakhnenko</a>,
        <a href="">Viktor Lempitsky</a>,
        <a href="">Egor Zakharov</a>
        <br>
        <em>ACMM</em>, 2022
        <br>
        <a href="https://neeek2303.github.io/MegaPortraits/">project page</a>
        /
        <a href="https://arxiv.org/abs/2207.07621">arXiv</a>
        /
        <a href="https://www.youtube.com/watch?v=9D5ulvdg0jM">video</a>
        <p></p>
        <p>In this work, we advance the neural head avatar technology to the megapixel resolution while focusing on the particularly challenging task of cross-driving synthesis, i.e., when the appearance of the driving image is substantially different from the animated source image.</p>
      </td>
    </tr> 




              
  <tr onmouseout="UDSR_stop()" onmouseover="UDSR_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <div class="two" id='UDSR_image'><video  width=100% height=100% muted autoplay loop>
        <source src="images/DD.png" type="video/mp4">
        Your browser does not support the video tag.
        </video></div>
        <img src='images/DD.png' width="160">
      </div>
      <script type="text/javascript">
        function UDSR_start() {
          document.getElementById('UDSR_image').style.opacity = "1";
        }

        function UDSR_stop() {
          document.getElementById('UDSR_image').style.opacity = "0";
        }
        UDSR_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://arxiv.org/abs/2105.12038">
        <span class="papertitle">Unpaired Depth Super-Resolution in the Wild</span>
      </a>
      <br>
      <a href="">Aleksandr Safin*</a>,
      <strong>Nikita Drobyshev*</strong>,
      <a href="">Maxim Kan*</a>,
      <a href="">Oleg Voynov</a>,
      <a href="">Alexey Artemov</a>,
      <a href="">Alexander Filippov</a>,
      <a href="">Denis Zorin</a>,
      <a href="">Evgeny Burnaev</a>,
      <br>
      <em>arXiv</em>, 2021
      <br>
      <a href="https://arxiv.org/abs/2105.12038">arXiv</a>
      <p></p>
      <p>
      We propose an unpaired learning method for depth super-resolution, which is based on a learnable degradation model, enhancement component and surface normal estimates as features to produce more accurate depth maps. 
      </p>
    </td>
  </tr>
	



              
    <tr onmouseout="brain_stop()" onmouseover="brain_stopt()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='brain_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/brain_2.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/brain_2.png' width="160">
        </div>
        <script type="text/javascript">
          function brain_start() {
            document.getElementById('brain_image').style.opacity = "1";
          }

          function brain_stop() {
            document.getElementById('brain_image').style.opacity = "0";
          }
          brain_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2105.12038">
			<span class="papertitle">Interpretation of 3D CNNs for Brain MRI Data Classification
</span>
        </a>
        <br> 
        <a href="">Maxim Kan</a>,
		<a href="">Ruslan Aliev</a>,
        <a href="">Anna Rudenko</a>,
        <strong>Nikita Drobyshev</strong>,
        <a href="">Nikita Petrashen</a>,
        <a href="">Ekaterina Kondrateva</a>,
        <a href="">Maxim Sharaev</a>,
        <a href="">Alexander Bernstein</a>,
        <a href="">Evgeny Burnaev</a>,
        <br>
        <em>AIST</em>, 2020
        <br>
        <a href="https://arxiv.org/abs/2105.12038">arXiv</a>
        <p></p>
        <p>
        We extend the previous findings in gender differences from diffusion-tensor imaging on T1 brain MRI scans. We provide the voxel-wise 3D CNN interpretation comparing the results of three interpretation methods: Meaningful Perturbations, Grad CAM and Guided Backpropagation, and contribute with the open-source library.
        </p>
      </td>
    </tr>



            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
